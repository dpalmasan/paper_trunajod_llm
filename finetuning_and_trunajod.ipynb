{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dcbb1dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "from spellchecker import SpellChecker\n",
    "import re\n",
    "from typing import List\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import TRUNAJOD.lexico_semantic_norms as lsn\n",
    "import TRUNAJOD.surface_proxies as sp\n",
    "import TRUNAJOD.semantic_measures as sm\n",
    "import TRUNAJOD.ttr as ttr\n",
    "import TRUNAJOD.givenness as gv\n",
    "import TRUNAJOD.utils as utils\n",
    "import TRUNAJOD.discourse_markers as dm\n",
    "import TRUNAJOD.entity_grid as eg\n",
    "import tarfile\n",
    "import pickle\n",
    "import spacy\n",
    "import es_core_news_lg\n",
    "import math\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6eede663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>level</th>\n",
       "      <th>TTR lemma</th>\n",
       "      <th>TTR noun</th>\n",
       "      <th>TTR verb</th>\n",
       "      <th>TTR function</th>\n",
       "      <th>TTR content</th>\n",
       "      <th>TTR adj</th>\n",
       "      <th>TTR adv</th>\n",
       "      <th>TTR prp</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_givenness_proj</th>\n",
       "      <th>min_givenness_proj</th>\n",
       "      <th>max_givenness_proj</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>avg_dist_to_centroid</th>\n",
       "      <th>max_dist_to_centroid</th>\n",
       "      <th>min_dist_to_centroid</th>\n",
       "      <th>std_distance</th>\n",
       "      <th>relative_distance</th>\n",
       "      <th>det_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Era se una vez un pequeño escorpión a la orill...</td>\n",
       "      <td>1B</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489610</td>\n",
       "      <td>0.280551</td>\n",
       "      <td>0.713717</td>\n",
       "      <td>0.250304</td>\n",
       "      <td>0.560975</td>\n",
       "      <td>0.729152</td>\n",
       "      <td>0.301215</td>\n",
       "      <td>14.183988</td>\n",
       "      <td>19.452718</td>\n",
       "      <td>4.588260e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La cigüeña Aída Agüero, gran creadora de sombr...</td>\n",
       "      <td>1B</td>\n",
       "      <td>0.414847</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.510210</td>\n",
       "      <td>0.382162</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.233579</td>\n",
       "      <td>0.577674</td>\n",
       "      <td>0.760125</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>14.367741</td>\n",
       "      <td>18.901802</td>\n",
       "      <td>-2.569041e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En el cuartel, los bomberos están siempre de g...</td>\n",
       "      <td>1B</td>\n",
       "      <td>0.364621</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.529138</td>\n",
       "      <td>0.389271</td>\n",
       "      <td>0.734457</td>\n",
       "      <td>0.290055</td>\n",
       "      <td>0.541887</td>\n",
       "      <td>0.708574</td>\n",
       "      <td>0.371756</td>\n",
       "      <td>14.569197</td>\n",
       "      <td>20.561280</td>\n",
       "      <td>-4.155671e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cierta vanidosa y acaudalada hormiga, preguntó...</td>\n",
       "      <td>1B</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.514968</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.708050</td>\n",
       "      <td>0.199517</td>\n",
       "      <td>0.562314</td>\n",
       "      <td>0.698117</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>14.367144</td>\n",
       "      <td>20.579861</td>\n",
       "      <td>-6.116545e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Había una vez un niño que era muy pobre, pero ...</td>\n",
       "      <td>1B</td>\n",
       "      <td>0.369099</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507178</td>\n",
       "      <td>0.384525</td>\n",
       "      <td>0.654537</td>\n",
       "      <td>0.281055</td>\n",
       "      <td>0.567783</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.369277</td>\n",
       "      <td>14.622747</td>\n",
       "      <td>21.222122</td>\n",
       "      <td>1.487500e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text level  TTR lemma  \\\n",
       "0  Era se una vez un pequeño escorpión a la orill...    1B   0.397163   \n",
       "1  La cigüeña Aída Agüero, gran creadora de sombr...    1B   0.414847   \n",
       "2  En el cuartel, los bomberos están siempre de g...    1B   0.364621   \n",
       "3  Cierta vanidosa y acaudalada hormiga, preguntó...    1B   0.390863   \n",
       "4  Había una vez un niño que era muy pobre, pero ...    1B   0.369099   \n",
       "\n",
       "   TTR noun  TTR verb  TTR function  TTR content   TTR adj   TTR adv  \\\n",
       "0  0.636364  0.900000      0.556522     0.761905  0.888889  0.800000   \n",
       "1  0.902439  0.833333      0.452055     0.885714  0.894737  0.857143   \n",
       "2  0.733333  0.950000      0.452830     0.768116  1.000000  0.600000   \n",
       "3  0.692308  0.736842      0.531250     0.754386  1.000000  0.777778   \n",
       "4  0.880000  0.730769      0.458333     0.840000  1.000000  0.500000   \n",
       "\n",
       "    TTR prp  ...  avg_givenness_proj  min_givenness_proj  max_givenness_proj  \\\n",
       "0  0.705882  ...            0.489610            0.280551            0.713717   \n",
       "1  0.714286  ...            0.510210            0.382162            0.642056   \n",
       "2  0.470588  ...            0.529138            0.389271            0.734457   \n",
       "3  0.750000  ...            0.514968            0.360757            0.708050   \n",
       "4  0.466667  ...            0.507178            0.384525            0.654537   \n",
       "\n",
       "     kl_div  avg_dist_to_centroid  max_dist_to_centroid  min_dist_to_centroid  \\\n",
       "0  0.250304              0.560975              0.729152              0.301215   \n",
       "1  0.233579              0.577674              0.760125              0.305093   \n",
       "2  0.290055              0.541887              0.708574              0.371756   \n",
       "3  0.199517              0.562314              0.698117              0.385223   \n",
       "4  0.281055              0.567783              0.689033              0.369277   \n",
       "\n",
       "   std_distance  relative_distance      det_dist  \n",
       "0     14.183988          19.452718  4.588260e-12  \n",
       "1     14.367741          18.901802 -2.569041e-08  \n",
       "2     14.569197          20.561280 -4.155671e-09  \n",
       "3     14.367144          20.579861 -6.116545e-07  \n",
       "4     14.622747          21.222122  1.487500e-08  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"shortener_trunajod_indices.xlsx\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3abcf055",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.replace([np.inf, -np.inf], np.nan)\n",
    "df_filtered = df_filtered.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "0a9523bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_map = {\n",
    "    \"1B\": 0,\n",
    "    \"2B\": 0,\n",
    "    \"3B\": 0,\n",
    "    \"4B\": 1,\n",
    "    \"5B\": 1,\n",
    "    \"6B\": 1,\n",
    "    \"7B\": 2,\n",
    "    \"8B\": 2,\n",
    "}\n",
    "df_filtered[\"group\"] = df[\"level\"].apply(lambda x: level_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "1b8d7e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>TTR lemma</th>\n",
       "      <th>TTR noun</th>\n",
       "      <th>TTR verb</th>\n",
       "      <th>TTR function</th>\n",
       "      <th>TTR content</th>\n",
       "      <th>TTR adj</th>\n",
       "      <th>TTR adv</th>\n",
       "      <th>TTR prp</th>\n",
       "      <th>TTR Diversidad léxica MTLD</th>\n",
       "      <th>...</th>\n",
       "      <th>min_givenness_proj</th>\n",
       "      <th>max_givenness_proj</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>avg_dist_to_centroid</th>\n",
       "      <th>max_dist_to_centroid</th>\n",
       "      <th>min_dist_to_centroid</th>\n",
       "      <th>std_distance</th>\n",
       "      <th>relative_distance</th>\n",
       "      <th>det_dist</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Era se una vez un pequeño escorpión a la orill...</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.556522</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>65.757323</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280551</td>\n",
       "      <td>0.713717</td>\n",
       "      <td>0.250304</td>\n",
       "      <td>0.560975</td>\n",
       "      <td>0.729152</td>\n",
       "      <td>0.301215</td>\n",
       "      <td>14.183988</td>\n",
       "      <td>19.452718</td>\n",
       "      <td>4.588260e-12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La cigüeña Aída Agüero, gran creadora de sombr...</td>\n",
       "      <td>0.414847</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>81.357096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382162</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.233579</td>\n",
       "      <td>0.577674</td>\n",
       "      <td>0.760125</td>\n",
       "      <td>0.305093</td>\n",
       "      <td>14.367741</td>\n",
       "      <td>18.901802</td>\n",
       "      <td>-2.569041e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>En el cuartel, los bomberos están siempre de g...</td>\n",
       "      <td>0.364621</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.452830</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>53.274510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389271</td>\n",
       "      <td>0.734457</td>\n",
       "      <td>0.290055</td>\n",
       "      <td>0.541887</td>\n",
       "      <td>0.708574</td>\n",
       "      <td>0.371756</td>\n",
       "      <td>14.569197</td>\n",
       "      <td>20.561280</td>\n",
       "      <td>-4.155671e-09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cierta vanidosa y acaudalada hormiga, preguntó...</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.708050</td>\n",
       "      <td>0.199517</td>\n",
       "      <td>0.562314</td>\n",
       "      <td>0.698117</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>14.367144</td>\n",
       "      <td>20.579861</td>\n",
       "      <td>-6.116545e-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Había una vez un niño que era muy pobre, pero ...</td>\n",
       "      <td>0.369099</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>47.623596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384525</td>\n",
       "      <td>0.654537</td>\n",
       "      <td>0.281055</td>\n",
       "      <td>0.567783</td>\n",
       "      <td>0.689033</td>\n",
       "      <td>0.369277</td>\n",
       "      <td>14.622747</td>\n",
       "      <td>21.222122</td>\n",
       "      <td>1.487500e-08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  TTR lemma  TTR noun  \\\n",
       "0  Era se una vez un pequeño escorpión a la orill...   0.397163  0.636364   \n",
       "1  La cigüeña Aída Agüero, gran creadora de sombr...   0.414847  0.902439   \n",
       "2  En el cuartel, los bomberos están siempre de g...   0.364621  0.733333   \n",
       "3  Cierta vanidosa y acaudalada hormiga, preguntó...   0.390863  0.692308   \n",
       "4  Había una vez un niño que era muy pobre, pero ...   0.369099  0.880000   \n",
       "\n",
       "   TTR verb  TTR function  TTR content   TTR adj   TTR adv   TTR prp  \\\n",
       "0  0.900000      0.556522     0.761905  0.888889  0.800000  0.705882   \n",
       "1  0.833333      0.452055     0.885714  0.894737  0.857143  0.714286   \n",
       "2  0.950000      0.452830     0.768116  1.000000  0.600000  0.470588   \n",
       "3  0.736842      0.531250     0.754386  1.000000  0.777778  0.750000   \n",
       "4  0.730769      0.458333     0.840000  1.000000  0.500000  0.466667   \n",
       "\n",
       "   TTR Diversidad léxica MTLD  ...  min_givenness_proj  max_givenness_proj  \\\n",
       "0                   65.757323  ...            0.280551            0.713717   \n",
       "1                   81.357096  ...            0.382162            0.642056   \n",
       "2                   53.274510  ...            0.389271            0.734457   \n",
       "3                   61.000000  ...            0.360757            0.708050   \n",
       "4                   47.623596  ...            0.384525            0.654537   \n",
       "\n",
       "     kl_div  avg_dist_to_centroid  max_dist_to_centroid  min_dist_to_centroid  \\\n",
       "0  0.250304              0.560975              0.729152              0.301215   \n",
       "1  0.233579              0.577674              0.760125              0.305093   \n",
       "2  0.290055              0.541887              0.708574              0.371756   \n",
       "3  0.199517              0.562314              0.698117              0.385223   \n",
       "4  0.281055              0.567783              0.689033              0.369277   \n",
       "\n",
       "   std_distance  relative_distance      det_dist  group  \n",
       "0     14.183988          19.452718  4.588260e-12      0  \n",
       "1     14.367741          18.901802 -2.569041e-08      0  \n",
       "2     14.569197          20.561280 -4.155671e-09      0  \n",
       "3     14.367144          20.579861 -6.116545e-07      0  \n",
       "4     14.622747          21.222122  1.487500e-08      0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_filtered.drop([\"level\"], axis=1)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6ecbbf",
   "metadata": {},
   "source": [
    "# Split Data\n",
    "\n",
    "We split the data into two groups. `X_train` will be used to train the models, `X_test` to evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "5cf234d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_train.drop([\"group\", \"text\"], axis=1),\n",
    "    df_train.group, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "1db5ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TTR lemma',\n",
       " 'TTR function',\n",
       " 'SM verb_syn_overlap',\n",
       " 'SM lexical_overlap',\n",
       " 'LSM concreteness',\n",
       " 'LSM imageability',\n",
       " 'LSM avg_context_availability',\n",
       " 'SP Promedio Longitud Palabras letra',\n",
       " 'SP Promedio Longitud Palabras sílaba',\n",
       " 'SP Densidad de VERB|AUX',\n",
       " 'r_distance',\n",
       " 'approx_spell_errors',\n",
       " 'avg_givenness_proj',\n",
       " 'kl_div',\n",
       " 'min_dist_to_centroid']"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_new = selector.transform(X_train)\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get the names of the selected features\n",
    "selected_columns = X_train.columns[selected_indices].tolist()\n",
    "X_test_new = pd.DataFrame(selector.transform(X_test), columns=selected_columns)\n",
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "dd772f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTR lemma</th>\n",
       "      <th>TTR function</th>\n",
       "      <th>SM verb_syn_overlap</th>\n",
       "      <th>SM lexical_overlap</th>\n",
       "      <th>LSM concreteness</th>\n",
       "      <th>LSM imageability</th>\n",
       "      <th>LSM avg_context_availability</th>\n",
       "      <th>SP Promedio Longitud Palabras letra</th>\n",
       "      <th>SP Promedio Longitud Palabras sílaba</th>\n",
       "      <th>SP Densidad de VERB|AUX</th>\n",
       "      <th>r_distance</th>\n",
       "      <th>approx_spell_errors</th>\n",
       "      <th>avg_givenness_proj</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>min_dist_to_centroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.346863</td>\n",
       "      <td>0.290640</td>\n",
       "      <td>2.892857</td>\n",
       "      <td>0.424731</td>\n",
       "      <td>3.622500</td>\n",
       "      <td>4.027188</td>\n",
       "      <td>4.627813</td>\n",
       "      <td>4.915493</td>\n",
       "      <td>2.126761</td>\n",
       "      <td>0.095775</td>\n",
       "      <td>5.853458</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.478693</td>\n",
       "      <td>0.467646</td>\n",
       "      <td>0.247011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.286432</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>1.758621</td>\n",
       "      <td>0.446281</td>\n",
       "      <td>5.228462</td>\n",
       "      <td>5.893846</td>\n",
       "      <td>5.695385</td>\n",
       "      <td>4.191406</td>\n",
       "      <td>1.871094</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>5.193512</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.480924</td>\n",
       "      <td>0.433080</td>\n",
       "      <td>0.360713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.334034</td>\n",
       "      <td>0.339623</td>\n",
       "      <td>2.631579</td>\n",
       "      <td>0.443820</td>\n",
       "      <td>3.548571</td>\n",
       "      <td>3.827381</td>\n",
       "      <td>4.754048</td>\n",
       "      <td>4.698052</td>\n",
       "      <td>2.064935</td>\n",
       "      <td>0.074675</td>\n",
       "      <td>4.577560</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.462817</td>\n",
       "      <td>0.358478</td>\n",
       "      <td>0.122269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.343699</td>\n",
       "      <td>0.359091</td>\n",
       "      <td>2.527273</td>\n",
       "      <td>0.381443</td>\n",
       "      <td>4.853571</td>\n",
       "      <td>5.816429</td>\n",
       "      <td>5.632857</td>\n",
       "      <td>4.563307</td>\n",
       "      <td>1.992248</td>\n",
       "      <td>0.162791</td>\n",
       "      <td>5.889199</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.457257</td>\n",
       "      <td>0.383632</td>\n",
       "      <td>0.251357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.360248</td>\n",
       "      <td>0.376000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.362745</td>\n",
       "      <td>4.866667</td>\n",
       "      <td>5.568000</td>\n",
       "      <td>5.926667</td>\n",
       "      <td>4.311628</td>\n",
       "      <td>1.851163</td>\n",
       "      <td>0.120930</td>\n",
       "      <td>4.243224</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.496650</td>\n",
       "      <td>0.372178</td>\n",
       "      <td>0.291991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTR lemma  TTR function  SM verb_syn_overlap  SM lexical_overlap  \\\n",
       "0   0.346863      0.290640             2.892857            0.424731   \n",
       "1   0.286432      0.313725             1.758621            0.446281   \n",
       "2   0.334034      0.339623             2.631579            0.443820   \n",
       "3   0.343699      0.359091             2.527273            0.381443   \n",
       "4   0.360248      0.376000             2.400000            0.362745   \n",
       "\n",
       "   LSM concreteness  LSM imageability  LSM avg_context_availability  \\\n",
       "0          3.622500          4.027188                      4.627813   \n",
       "1          5.228462          5.893846                      5.695385   \n",
       "2          3.548571          3.827381                      4.754048   \n",
       "3          4.853571          5.816429                      5.632857   \n",
       "4          4.866667          5.568000                      5.926667   \n",
       "\n",
       "   SP Promedio Longitud Palabras letra  SP Promedio Longitud Palabras sílaba  \\\n",
       "0                             4.915493                              2.126761   \n",
       "1                             4.191406                              1.871094   \n",
       "2                             4.698052                              2.064935   \n",
       "3                             4.563307                              1.992248   \n",
       "4                             4.311628                              1.851163   \n",
       "\n",
       "   SP Densidad de VERB|AUX  r_distance  approx_spell_errors  \\\n",
       "0                 0.095775    5.853458                 74.0   \n",
       "1                 0.128906    5.193512                 40.0   \n",
       "2                 0.074675    4.577560                 61.0   \n",
       "3                 0.162791    5.889199                 83.0   \n",
       "4                 0.120930    4.243224                 49.0   \n",
       "\n",
       "   avg_givenness_proj    kl_div  min_dist_to_centroid  \n",
       "0            0.478693  0.467646              0.247011  \n",
       "1            0.480924  0.433080              0.360713  \n",
       "2            0.462817  0.358478              0.122269  \n",
       "3            0.457257  0.383632              0.251357  \n",
       "4            0.496650  0.372178              0.291991  "
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_new = pd.DataFrame(X_train_new, columns=selected_columns)\n",
    "X_train_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "055619e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for group in y_train:\n",
    "    clusters[group] = X_train_new.values[y_train == group].mean(axis=0)\n",
    "    clusters[group] /= np.linalg.norm(clusters[group])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "6e4af3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for _, cluster in clusters.items():\n",
    "    print(np.linalg.norm(cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "95fb8742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;background-color: white;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=10)\n",
    "neigh.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "b5c0213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = neigh.predict(X_test_new)\n",
    "accuracy_nn = accuracy_score(y_test, y_pred_nn)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_nn * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "ae4c6723",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_norm = X_test_new / np.linalg.norm(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "f5673ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_trj_cluster = []\n",
    "for X_sample in X_test_norm.values:\n",
    "    min_dist = float(\"inf\")\n",
    "    pred_group = -1\n",
    "    for cluster, group in clusters.items():\n",
    "        dist = np.linalg.norm(X_sample - group)\n",
    "        if dist < min_dist:\n",
    "            pred_group = cluster\n",
    "            min_dist = dist\n",
    "    y_pred_trj_cluster.append(pred_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "640a1dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 61.36%\n"
     ]
    }
   ],
   "source": [
    "accuracy_trj = accuracy_score(y_test, y_pred_trj_cluster)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_trj * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "dd412018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=None,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4)\n",
    "xgb.fit(X_train_new, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "88ed52a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.421756\n",
      "0    0.301527\n",
      "2    0.276718\n",
      "Name: group, dtype: float64\n",
      "0    0.378788\n",
      "1    0.371212\n",
      "2    0.250000\n",
      "Name: group, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts(True))\n",
    "print(y_test.value_counts(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "e3ef5959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.85%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb.predict(X_test_new)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "49ffd93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_mapping = {\n",
    "    0: \"group_123B\",\n",
    "    1: \"group_456B\",\n",
    "    2: \"group_78B\",\n",
    "}\n",
    "\n",
    "groups = df_train.group.apply(lambda x: group_mapping[x])\n",
    "data = list(zip(df_train.text, groups, df_train[selected_columns].values))\n",
    "train_portion = 0.8\n",
    "train_idx = int(len(data) * train_portion)\n",
    "\n",
    "random.shuffle(data)\n",
    "train_data = data[0:train_idx]\n",
    "test_data = data[train_idx:]\n",
    "assert len(train_data) + len(test_data) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "4b86293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"train_data.jsonl\", \"w\") as fp:\n",
    "    for text, group in train_data:\n",
    "        prompt = (\n",
    "            \"Clasifica el siguiente texto en uno de los siguientes estilos: group_123B, group_456B, group_78B.\\n\\n\"\n",
    "             f\"Texto: {text}\\n\\n\"\n",
    "             \"Estilo:\")\n",
    "        session = {\"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{group}\", \"weight\": 1}]}\n",
    "        jsonl = json.dumps(session, ensure_ascii=False)\n",
    "        fp.write(f\"{jsonl}\\n\")\n",
    "        \n",
    "with open(\"test_data.jsonl\", \"w\") as fp:\n",
    "    for text, group in test_data:\n",
    "        prompt = (\n",
    "            \"Clasifica el siguiente texto en uno de los siguientes estilos: group_123B, group_456B, group_78B.\\n\\n\"\n",
    "             f\"Texto: {text}\\n\\n\"\n",
    "             \"Estilo:\")\n",
    "        session = {\"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": f\"{group}\", \"weight\": 1}]}\n",
    "        jsonl = json.dumps(session, ensure_ascii=False)\n",
    "        fp.write(f\"{jsonl}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "ef9d1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"your key\")\n",
    "client = openai.OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "795ea12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-FDGf8KW5U2tPoPmt3FBxiu', bytes=1186413, created_at=1737236988, filename='train_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.files.create(\n",
    "  file=open(\"train_data.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "a7becc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-xm48F5TkevqnIJcD0VFzyZKf', created_at=1737237062, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-2024-08-06', object='fine_tuning.job', organization_id='org-JihYzTh2GjJjoPtZZ0kQdsbr', result_files=[], seed=1510144633, status='validating_files', trained_tokens=None, training_file='file-FDGf8KW5U2tPoPmt3FBxiu', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None, method={'type': 'supervised', 'supervised': {'hyperparameters': {'batch_size': 'auto', 'learning_rate_multiplier': 'auto', 'n_epochs': 'auto'}}})"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job = client.fine_tuning.jobs.create(\n",
    "    training_file=\"file-FDGf8KW5U2tPoPmt3FBxiu\",\n",
    "    model=\"gpt-4o-2024-08-06\",\n",
    ")\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "id": "454eb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_text(text):\n",
    "    prompt = (\n",
    "            \"Clasifica el siguiente texto en uno de los siguientes estilos: group_123B, group_456B, group_78B.\\n\\n\"\n",
    "             f\"Texto: {text}\\n\\n\"\n",
    "             \"Estilo:\")\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"ft:gpt-4o-2024-08-06:personal::ArBmNsh6\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "0697b49c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(524, 132)"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "18858207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 524/524 [05:17<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "groups = []\n",
    "ft_class = []\n",
    "trj_vals = []\n",
    "for text, group, trj_val in tqdm(train_data, total=len(train_data)):\n",
    "    response = classify_text(text)\n",
    "    ft_class.append(response.choices[0].message.content)\n",
    "    groups.append(group)\n",
    "    trj_vals.append(trj_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "6c97e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'group_advanced', 'group_basic', 'group_medium'},\n",
       " {'**group_medium', 'group_advanced', 'group_basic', 'group_medium'})"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = {\n",
    "    \"group_123B\": \"group_basic\",\n",
    "    \"group_456B\": \"group_medium\",\n",
    "    \"group_78B\": \"group_advanced\",\n",
    "}\n",
    "\n",
    "norm_groups = list(map(lambda x: mapping[x], groups))\n",
    "set(norm_groups), set(ft_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "9e3bef80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'group_advanced', 'group_basic', 'group_medium'}"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_ft_class = []\n",
    "for c in ft_class:\n",
    "    for cc in list(set(norm_groups)):\n",
    "        if cc in c:\n",
    "            cleaned_ft_class.append(cc)\n",
    "set(cleaned_ft_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "28e7a1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8110687022900763"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([g in ft for ft, g in zip(ft_class, norm_groups)]) / len(ft_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "067125db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTR lemma</th>\n",
       "      <th>TTR function</th>\n",
       "      <th>SM verb_syn_overlap</th>\n",
       "      <th>SM lexical_overlap</th>\n",
       "      <th>LSM concreteness</th>\n",
       "      <th>LSM imageability</th>\n",
       "      <th>LSM avg_context_availability</th>\n",
       "      <th>SP Promedio Longitud Palabras letra</th>\n",
       "      <th>SP Promedio Longitud Palabras sílaba</th>\n",
       "      <th>SP Densidad de VERB|AUX</th>\n",
       "      <th>r_distance</th>\n",
       "      <th>approx_spell_errors</th>\n",
       "      <th>avg_givenness_proj</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>min_dist_to_centroid</th>\n",
       "      <th>gpt4_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.309689</td>\n",
       "      <td>0.294521</td>\n",
       "      <td>2.047619</td>\n",
       "      <td>0.382812</td>\n",
       "      <td>2.989524</td>\n",
       "      <td>3.393810</td>\n",
       "      <td>4.199524</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>2.861582</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>5.234709</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.457392</td>\n",
       "      <td>0.489791</td>\n",
       "      <td>0.338166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>3.937500</td>\n",
       "      <td>4.162500</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>4.433824</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>3.698460</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.514513</td>\n",
       "      <td>0.220831</td>\n",
       "      <td>0.370393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.312178</td>\n",
       "      <td>0.295964</td>\n",
       "      <td>2.096774</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>3.123704</td>\n",
       "      <td>2.784815</td>\n",
       "      <td>4.562963</td>\n",
       "      <td>4.479275</td>\n",
       "      <td>1.987047</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>6.339204</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.478390</td>\n",
       "      <td>0.561491</td>\n",
       "      <td>0.272437</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.305128</td>\n",
       "      <td>0.270175</td>\n",
       "      <td>2.405405</td>\n",
       "      <td>0.366795</td>\n",
       "      <td>4.533437</td>\n",
       "      <td>5.111875</td>\n",
       "      <td>5.304687</td>\n",
       "      <td>4.545635</td>\n",
       "      <td>1.920635</td>\n",
       "      <td>0.085317</td>\n",
       "      <td>6.858405</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.457211</td>\n",
       "      <td>0.571003</td>\n",
       "      <td>0.275237</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.274956</td>\n",
       "      <td>0.282486</td>\n",
       "      <td>1.529412</td>\n",
       "      <td>0.225641</td>\n",
       "      <td>5.677742</td>\n",
       "      <td>6.160000</td>\n",
       "      <td>5.601613</td>\n",
       "      <td>4.174157</td>\n",
       "      <td>1.893258</td>\n",
       "      <td>0.146067</td>\n",
       "      <td>5.279514</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.447640</td>\n",
       "      <td>0.543874</td>\n",
       "      <td>0.315711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTR lemma  TTR function  SM verb_syn_overlap  SM lexical_overlap  \\\n",
       "0   0.309689      0.294521             2.047619            0.382812   \n",
       "1   0.406699      0.523810             2.187500            0.311475   \n",
       "2   0.312178      0.295964             2.096774            0.360215   \n",
       "3   0.305128      0.270175             2.405405            0.366795   \n",
       "4   0.274956      0.282486             1.529412            0.225641   \n",
       "\n",
       "   LSM concreteness  LSM imageability  LSM avg_context_availability  \\\n",
       "0          2.989524          3.393810                      4.199524   \n",
       "1          3.937500          4.162500                      5.190000   \n",
       "2          3.123704          2.784815                      4.562963   \n",
       "3          4.533437          5.111875                      5.304687   \n",
       "4          5.677742          6.160000                      5.601613   \n",
       "\n",
       "   SP Promedio Longitud Palabras letra  SP Promedio Longitud Palabras sílaba  \\\n",
       "0                             5.666667                              2.861582   \n",
       "1                             4.433824                              2.000000   \n",
       "2                             4.479275                              1.987047   \n",
       "3                             4.545635                              1.920635   \n",
       "4                             4.174157                              1.893258   \n",
       "\n",
       "   SP Densidad de VERB|AUX  r_distance  approx_spell_errors  \\\n",
       "0                 0.073446    5.234709                 79.0   \n",
       "1                 0.132353    3.698460                 31.0   \n",
       "2                 0.119171    6.339204                 61.0   \n",
       "3                 0.085317    6.858405                132.0   \n",
       "4                 0.146067    5.279514                 70.0   \n",
       "\n",
       "   avg_givenness_proj    kl_div  min_dist_to_centroid  gpt4_pred  \n",
       "0            0.457392  0.489791              0.338166          1  \n",
       "1            0.514513  0.220831              0.370393          0  \n",
       "2            0.478390  0.561491              0.272437          1  \n",
       "3            0.457211  0.571003              0.275237          1  \n",
       "4            0.447640  0.543874              0.315711          0  "
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_to_class = {\n",
    "    \"group_basic\": 0,\n",
    "    \"group_medium\": 1,\n",
    "    \"group_advanced\": 2,\n",
    "}\n",
    "\n",
    "xgb_groups_train = list(map(lambda x: mapping_to_class[x], cleaned_ft_class))\n",
    "df_train_ft = pd.DataFrame([t[2] for t in train_data], columns=selected_columns)\n",
    "df_train_ft[\"gpt4_pred\"] = xgb_groups_train\n",
    "df_train_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "2a2633c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;background-color: white;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(df_train_ft, xgb_groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "430fe443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 132/132 [02:24<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "test_groups = []\n",
    "test_ft_class = []\n",
    "test_trj_vals = []\n",
    "for text, group, trj_val in tqdm(test_data, total=len(test_data)):\n",
    "    response = classify_text(text)\n",
    "    test_ft_class.append(response.choices[0].message.content)\n",
    "    test_groups.append(group)\n",
    "    test_trj_vals.append(test_trj_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "c1d5a883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 132, 0)"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_groups), len(test_ft_class), len(test_trj_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "aa85f5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'group_advanced', 'group_basic', 'group_medium'}, 132)"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cleaned_ft_class = []\n",
    "append_called = False\n",
    "for c in test_ft_class:\n",
    "    for cc in list(set(norm_groups)):\n",
    "        if cc in c:\n",
    "            test_cleaned_ft_class.append(cc)\n",
    "            append_called = True\n",
    "    if not append_called:\n",
    "        test_cleaned_ft_class.append(\"group_basic\")\n",
    "    append_called = False\n",
    "    \n",
    "            \n",
    "set(test_cleaned_ft_class), len(test_cleaned_ft_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "885c7d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_norm_groups = list(map(lambda x: mapping[x], test_groups))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "8c709336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18893129770992367"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([g in ft for ft, g in zip(test_cleaned_ft_class, test_norm_groups)]) / len(ft_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "b002da59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TTR lemma</th>\n",
       "      <th>TTR function</th>\n",
       "      <th>SM verb_syn_overlap</th>\n",
       "      <th>SM lexical_overlap</th>\n",
       "      <th>LSM concreteness</th>\n",
       "      <th>LSM imageability</th>\n",
       "      <th>LSM avg_context_availability</th>\n",
       "      <th>SP Promedio Longitud Palabras letra</th>\n",
       "      <th>SP Promedio Longitud Palabras sílaba</th>\n",
       "      <th>SP Densidad de VERB|AUX</th>\n",
       "      <th>r_distance</th>\n",
       "      <th>approx_spell_errors</th>\n",
       "      <th>avg_givenness_proj</th>\n",
       "      <th>kl_div</th>\n",
       "      <th>min_dist_to_centroid</th>\n",
       "      <th>gpt4_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.354486</td>\n",
       "      <td>0.380435</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>3.789565</td>\n",
       "      <td>4.036087</td>\n",
       "      <td>5.307391</td>\n",
       "      <td>4.818792</td>\n",
       "      <td>2.120805</td>\n",
       "      <td>0.110738</td>\n",
       "      <td>5.847132</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.503207</td>\n",
       "      <td>0.438893</td>\n",
       "      <td>0.262880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.298153</td>\n",
       "      <td>0.334630</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.372951</td>\n",
       "      <td>4.985556</td>\n",
       "      <td>5.562963</td>\n",
       "      <td>5.282222</td>\n",
       "      <td>4.539278</td>\n",
       "      <td>1.991507</td>\n",
       "      <td>0.148620</td>\n",
       "      <td>6.991246</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.451355</td>\n",
       "      <td>0.536036</td>\n",
       "      <td>0.229948</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.376900</td>\n",
       "      <td>0.484127</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>3.515714</td>\n",
       "      <td>3.868571</td>\n",
       "      <td>5.021429</td>\n",
       "      <td>5.108491</td>\n",
       "      <td>2.188679</td>\n",
       "      <td>0.127358</td>\n",
       "      <td>4.493285</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.477109</td>\n",
       "      <td>0.251999</td>\n",
       "      <td>0.295672</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.255875</td>\n",
       "      <td>0.240678</td>\n",
       "      <td>1.979592</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>3.120682</td>\n",
       "      <td>3.244091</td>\n",
       "      <td>4.348636</td>\n",
       "      <td>4.842742</td>\n",
       "      <td>2.100806</td>\n",
       "      <td>0.114919</td>\n",
       "      <td>6.018451</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.420478</td>\n",
       "      <td>0.587276</td>\n",
       "      <td>0.349777</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.341040</td>\n",
       "      <td>0.417266</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.281429</td>\n",
       "      <td>4.965000</td>\n",
       "      <td>5.322857</td>\n",
       "      <td>4.233480</td>\n",
       "      <td>1.872247</td>\n",
       "      <td>0.096916</td>\n",
       "      <td>4.255356</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.467881</td>\n",
       "      <td>0.357677</td>\n",
       "      <td>0.243728</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TTR lemma  TTR function  SM verb_syn_overlap  SM lexical_overlap  \\\n",
       "0   0.354486      0.380435             2.440000            0.354610   \n",
       "1   0.298153      0.334630             1.857143            0.372951   \n",
       "2   0.376900      0.484127             2.700000            0.413462   \n",
       "3   0.255875      0.240678             1.979592            0.523622   \n",
       "4   0.341040      0.417266             2.200000            0.333333   \n",
       "\n",
       "   LSM concreteness  LSM imageability  LSM avg_context_availability  \\\n",
       "0          3.789565          4.036087                      5.307391   \n",
       "1          4.985556          5.562963                      5.282222   \n",
       "2          3.515714          3.868571                      5.021429   \n",
       "3          3.120682          3.244091                      4.348636   \n",
       "4          4.281429          4.965000                      5.322857   \n",
       "\n",
       "   SP Promedio Longitud Palabras letra  SP Promedio Longitud Palabras sílaba  \\\n",
       "0                             4.818792                              2.120805   \n",
       "1                             4.539278                              1.991507   \n",
       "2                             5.108491                              2.188679   \n",
       "3                             4.842742                              2.100806   \n",
       "4                             4.233480                              1.872247   \n",
       "\n",
       "   SP Densidad de VERB|AUX  r_distance  approx_spell_errors  \\\n",
       "0                 0.110738    5.847132                 66.0   \n",
       "1                 0.148620    6.991246                105.0   \n",
       "2                 0.127358    4.493285                 60.0   \n",
       "3                 0.114919    6.018451                 71.0   \n",
       "4                 0.096916    4.255356                 33.0   \n",
       "\n",
       "   avg_givenness_proj    kl_div  min_dist_to_centroid  gpt4_pred  \n",
       "0            0.503207  0.438893              0.262880          1  \n",
       "1            0.451355  0.536036              0.229948          1  \n",
       "2            0.477109  0.251999              0.295672          0  \n",
       "3            0.420478  0.587276              0.349777          2  \n",
       "4            0.467881  0.357677              0.243728          0  "
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_groups_test = list(map(lambda x: mapping_to_class[x], test_cleaned_ft_class))\n",
    "df_test_ft = pd.DataFrame([t[2] for t in test_data], columns=selected_columns)\n",
    "df_test_ft[\"gpt4_pred\"] = xgb_groups_test\n",
    "df_test_ft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "8ead8106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_ft_trj = xgb.predict(df_test_ft)\n",
    "y_test_ft = list(map(lambda x: mapping_to_class[x], test_norm_groups))\n",
    "accuracy_score(y_test_ft, preds_ft_trj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "2ce4f488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-33 {color: black;background-color: white;}#sk-container-id-33 pre{padding: 0;}#sk-container-id-33 div.sk-toggleable {background-color: white;}#sk-container-id-33 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-33 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-33 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-33 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-33 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-33 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-33 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-33 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-33 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-33 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-33 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-33 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-33 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-33 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-33 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-33 div.sk-item {position: relative;z-index: 1;}#sk-container-id-33 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-33 div.sk-item::before, #sk-container-id-33 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-33 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-33 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-33 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-33 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-33 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-33 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-33 div.sk-label-container {text-align: center;}#sk-container-id-33 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-33 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-33\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" checked><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=1000, n_jobs=None, nthread=4,\n",
       "              num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_trj = df_train_ft.drop([\"gpt4_pred\"], axis=1)\n",
    "xgb2 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=1000,\n",
    "    max_depth=10,\n",
    "    min_child_weight=1,\n",
    "    gamma=0,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='multi:softprob',\n",
    "    nthread=4)\n",
    "xgb2.fit(df_train_trj, xgb_groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "1318d02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_trj = df_test_ft.drop([\"gpt4_pred\"], axis=1)\n",
    "preds_trj = xgb2.predict(df_test_trj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "956c37bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6060606060606061"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_ft, preds_trj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c17c63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
